 # 《机器学习》`2024-09-13` `(三)409`

## P1

- 来自老师的强烈建议
  - 由于这门课很多学院一起开，不同学院考核方式不同，而我们这门课是软件学院开设的
  - 因此强烈建议计算机的同学去选自己学院的《机器学习》课程
    - （`GGN_2015` 心理描写：我要是能选上自己学院的课的话我会来您这里？）
- 作业
  - 将会在 “**智学北航 app**” 发布
- 课程目标
  - 了解机器学习的基本原理以及当前的发展情况
  - 使用机器学习解决自己领域的实际问题
  - 为相关工程实践打基础
- 参考书目
  - PRML、李航《统计学习方法》、Tom M Mitchell《ML》、西瓜书
- 前置课程
  - 工科数学分析，高等代数，概率统计
- 考核方式
  - 平时成绩 65% + 期末论文 35%
  - 期末论文
    - 题目自拟，其中确定题目期中交由助教评审，期末提交
    - 论文格式采用 CVPR 风格模板，6 页双烂正文（参考文献不占总页数）
    - 申优答辩：5 min PPT 视频讲解，5 分
    - 没有补考
- 什么是机器学习
  - 司马贺《机器应该学什么》
    - 所谓学习指的取出系统所产生的适应性变换，这种变化使得下一次传统再完成同种任务时表现得比上一次更有效
  - Tom M Mitchell
    - 经验 E、任务 T、性能指标 P
    - 随 E 增多，在 P 的视角下，任务 T 以更优秀的性能指标完成
  - 概率视角
    - 机器学习中的未知量一般都可以理解为随机变量
    - 机器学习，学习得实际上数据中某个随机变量的概率分布情况
  - 机器学习与人工智能的关系
    - 人工智能包含深度学习
    - 但与深度学习的其他方向不同，机器学习不强调应用场景，是抽象化的解决问题的思路
- 日常生活中深度学习的应用
  - OCR与手写数字识别（本质上是分类问题）
  - 人脸识别、微笑检测
  - 生物识别：指纹、人脸、声纹
  - 语音识别、同声传译
  - 推荐系统
  - 高频量化交易

## P2

- 深度学习领域的新突破
  - Generative Foundation Model
  - 大模型 + 生成式模型：GPT、生成式图像构建（Stable diffusion、sora）
- 在经典的机器学习算法中
  - 算法往往不能保证其性能随数据量的增加而持续增加
- CS231n：Andrej Karpathy
  - 提出了一些问题到现在也没有得到很好的解决
- 机器学习的通用流水线
  - 测试 -> 输入样本 -> 系统 -> 预测结果
  - 训练 -> 输入样本 -> 学习算法 -> 系统
- MNIST，Yann LeCun，手写数字识别
  - 样本 + 标签（有监督学习）
    - 按照一定比例划分测试集和训练集
    - 我们希望训练集和测试集具有相同的概率分布
  - 独立同分布是很多机器学习问题对于数据数据的一大假设
- 什么是特征
  - 原始数据可能难以直接被学习
  - 在概念上，存在更合适的针对输入样本数据的新的表示，这种表示是原始信息的函数
- 为什么有时候我们把拟合类问题称为回归问题
  - 达尔文时期有个人做了一个孩子身高和父母身高之间联系的实验
  - 他发现即使父母身高比较高，孩子身高往往还是有 “回归” 于社会平均水平的趋势

|      | 有监督 | 无监督 |
| ---- | ------ | ------ |
| 离散 | 分类   | 聚类   |
| 连续 | 回归   | 降维   |

- 有监督学习
  - 数据带标签，标签参与训练
- 无监督学习
  - 数据不带标签，我们只需要给出某个对象从属于某个聚类的 “可能性”

## P3

- 半监督学习
  - 部分数据带标签，但是我们希望给出所有数据整体数据集上的决策边界
- 强化学习
  - 只告诉它对错，不告诉它正确答案
  - 适合于类似棋类游戏等问题
    - 这类问题有明确的胜利条件
    - 但对于某个中间步骤，我们难以论证到底怎么做才是绝对正确的
- 其他形形色色的学习思路
  - 多标签、多对象、多任务学习
  - 迁移学习
  - 联邦学习（保证隐私的前提下、实现一种分布式的学习策略）
  - 终生学习（放置模型学着学着忘了旧的知识）
  - 上下文学习（描述大模型对语言的理解能力）
- 训练、评估以及目标
  - 划分训练集与测试集
  - 不能仅仅凭借训练集评价模型性能
  - 测试集和验证集功能不同
- 例子：多项式拟合问题
  - 一般而言
    - 模型越复杂，训练误差越小，但测试误差先变小后变大
    - 过拟合：过分的拟合了训练集中的噪声信息
    - 没有免费午餐定理
      - 所有模型都是错的
      - 但是其中有一些能拿来使用
    - 人类知识在解决过拟合问题上是至关重要的
    - 常见误差情况
      - $E_{out}(g)\leq E_{in}(g)\pm O\left(\sqrt {\frac{d_{vc}}{N}\ln N}\right)$
      - 其中 $d_{vc}$ 为模型本身的 “维数”，即其复杂程度
- 区分两种误差
  - Bias：由于模型本身能力不足而导致的先天偏见，欠拟合
  - Variance：由于模型表达能力过强，导致无法适应噪声，导致不同训练集测试机划分下模型有较大抖动，过拟合
- 解决方式
  - 稍微调大模型超参以保证模型本身的表达能力足够
  - 减小 Variance
    - 加入必要的正则化项
    - 进行必要的数据增广

## 其他互动

- 问：老师您手写数字识别那页 PPT 上是不是和您说的数不一样啊？不是什么大问题，但是我觉得从严谨的角度上来讲最好改一下之类的。（不同数字数量分布情况有所差异，但是老师上课时说没有差异。）
  - 答：确实，我回头改一下图。
- 问：我个人觉得最近 `ChatGPT-o1` 的出现让我觉得我的就业情况受到了威胁 ，听说在不限制提交次数的前提下 `ChatGPT` 已经能够在 IOI 的赛题上拿到金牌了，是这样吗？
  - 答：是的，我之前打 ACM 的学生也和我说，自己学了十多年的竞赛，被 ChatGPT 用这么短的时间就超过了，很不甘心。

